# 应用系统体系架构

$$
Wang \ Haotian
$$

 ## 10.21 Security

微服务本身不在乎请求从哪里过来的，通过GateWay隔离之后请求没有差异

### Kerberos协议

交大财务调用认证中心，认证中心有两个功能：

1. 认证：你是谁（AS）
2. 授权：你能干什么（TGS）Ticker Granting Server



认证授权部署在同一个服务器上，只做单点认证



Kerbos协议的流程（PPT security第62张的图）

1. 用户想要访问交大财务，现在有一个认证中心的服务器
2. 用户在客户端输入UserId和Pwd
3. UserId发送给AS，Pwd留在本地经过hash产生一个key_user
4. 服务器段根据UserId找到一个user，经过相同的hash算法产生一个key_as
5. key不能在网络上传输的，若AS用key_as加密一个东西（session key，一段时间内有效），user可以拿自己的key_user解密，说明密码对了
6. AS认证之后要进行授权，需要和TGS交互，不能明文交互。AS产生一个session key，通过刚才AS生成的key进行加密，用户拿到session key之后和TGS交互，但是是否相互信任？看下变的流程
7. TGS用TGS的pub_key加密一个session key产生message_b
8. user不能解开message_b，则原封不动传回去，把session key和message_b发回去
9. session key用TGS_pubkey加密之后产生message_c，把UserId和timestamp用session key加密之后产生message_d
10. TGS拿自己的private key解密得到session key，再用session key解密message_d得到信息，知道你在什么时候想要访问
11. 接着TGS进入TGS的数据库查权限信息，有权限才接着进行下一步
12. TGS会生成一个新的key，用于user和交大财务交互
13. TGS用session key加密上边说的user和交大财务交互的key，称message_f，传给user，user就可以用session key解开然后拿到key
14. TGS生成message_e，用交大财务的pub_key加密user和交大财务交互的key，同时附带user client的IP等信息
15. user解密message_f之后，没有交大财务的private key，所以message_e解不开，把message_e原封不动的发回来，交大财务解开之后能拿到client的信息和密钥
16. 用户再发给交大财务client一个message_g，包含client信息，用user和交大财务交互的key加密。交大财务已经有了这个key，因此可以拿到信息
17. 由于TGS是用交大财务的pub_key加密的，所以这个肯定是一个真的网站，不是一个钓鱼网站
18. 交大财务用user和交大财务交互的key加密每次user发来的时间戳+1，称为message_h，client可以检查这个时间戳对不对，以验证交大财务server对不对。



为什么叫单点认证？

AS认证只做一次



局限性：

多跑几个AS和TGS分布式实例，不然就裂开



Kerberos三头狗：

Client、AS/TGS、Service Server相互制约

### 安全

常见攻击手段：

- 跨站脚本攻击：比如一个文本输入框里边输入脚本
- 注入式攻击：密码框输入必定为真的sql脚本
- 分布式拒绝服务攻击（DDOS）：脚本同时动作，发大量请求搞坏服务器



抵御用户的跨站脚本攻击：

1. 把脚本的符号转义掉
2. 富文本编辑器，当文本展示，不当脚本运行

防止注入式攻击：

1. 不要用statement拼sql字符串方式进行JDBC的访问

防止分布式拒绝服务攻击：

1. 同一个IP多少时间内限定访问（但是不同机器就不行了）
2. 做好访问检测



安全的手段：

1. 密文存储
2. 链路加密
3. 维护数据完整性（hash，checksum）
4. 代码有限暴露（尽量所有都是private），封装接口，多个接口合为一个
5. 配置防火墙
6. 入侵检测系统（抓所有的包进行检测）
7. 恢复，打ckpt
8. 日志工具



## 10.25 MySQL Opt

**首先记住一点，数据库的东西在硬盘上存，访问时一定要load到memory，内存比硬盘小，且存在数据不一致，这是一切复杂性的根源**



索引，数据库结构，表的结构，字段设置等

OLAP，在线分析处理，列存比较合适

OLTP，在线事务处理，行存比较合适



### 索引

索引建树的类型

- 索引优化：B+树

- 地理位置索引：R-tree，空间索引是一个地理位置的值，经纬度、海拔、投影值等等很多信息

- MEMORY table支持哈希索引（hash会占用空间）

- InnoDB反向索引实现搜索引擎



索引的注意事项

- 多列索引的排序很重要

- 在查找时，索引文件load到内存里，再内存中搜索，如果索引文件很大，还得把当前这一页换出去，会有额外空间、时间的开销

- 数据量很小的时候建索引，效果提升不明显

- 索引太长，可以做前缀索引。

- 在批量操作，几乎操作所有数据时，索引没有太大意义

- InnoDB在disk上存数据时是按照主键索引的顺序存储的

- 主键要保证绝对唯一，如果是多列联合主键，会增加复杂性



关于全局唯一标识符：

在服务器集群时，可以用全局唯一标识符例如UUID，防止自增主键的重复，UUID是32位16进制数，一共16字节。但是UUID占用空间比较大，而且不能知道插入的先后顺序，若需要时间信息，需要加入额外时间戳。



关于外键：

1. 给不常用的列可以进行分表，外键关联，便于每次向内存加载更多数据，每次不需要从硬盘加载大量数据。否则对常用列的操作性能会降低。
2. 主键要尽量简单，会用其他表的主键当外键



关于前缀索引：

MySQL会对数据做压缩，根据存储方式的不同，前缀索引的长度可以不同



关于多列复合索引：

1. 最多支持16个列，没什么特别限制
2. 查询时匹配的顺序时建索引时的顺序，跳过第一列直接搜索第二列，索引就废了
3. JPA使用数据库的速度可能没那么高，JPA翻译的sql语句可能和预想的不同



关于Hash索引：

不能做范围查找，但是单个查找非常快，order by是不行的



关于索引顺序：

- B+树索引，默认升序，也可以设置为倒序
- 在进行Order By操作时，如果和索引的顺序是相同的，就不需要排序，节省一点时间



### 数据库设计

数据尺寸：

- 数据量尽量小一点=>数据压缩
- 表的列
- 行的格式
- 索引
- Join操作
- 范式化（衡量数据的冗余度，范式化越高数据冗余越小，但是性能可能会变差，因为外键操作特别多，join操作也很多）



表的列：

- 适合它的最小类型
- 尽量不让列为null，可能的话生成not null，null不利于索引，同时占用额外空间，还不利于编程



行结构：

- 可以对行进行一点压缩/Compact（Compact不一定要用压缩算法去压缩，而是一种Compact的表示，在时序数据库中也有体现）



索引：

- 主键索引越短越好，因为外键要存
- 组合索引比多个单独索引要好，因为组合索引是一整个！插入操作不用调整很多个树
- 总的索引越少越好，否则增加插入开销



Join：

- 拆表做join，减少冗余



范式化：

- 去冗余
- 数据同步问题



## 10.28 MySQL Opt

### 数据类型选择

- 能用数字，不用字符串
- 文本内容很多，不如存成Text或Blob
- 行的尺寸有限制，小于8k可以用varchar，否则一定要用text或者blob，因为一页16k（假设是16k），带上其他数据之后，一行可能存不下
- 主键选择，当一行数据很多时，UUID的空间占用是可以接受的，但是UUID之间无法比较先后顺序
- blob可以设置懒加载，有关blob的表可以专门设置一台机器或者硬盘，和其他经常存取的数据区分开
- blob的比较可以，可以比较摘要，长字符串比较效率很低



### MySQL的设置相关

- table open cache

- 建表、建库的数量和文件系统有关，但是同时打开的表的数量与cache有关，超出上限会告诉你打开表的数量达到上限，暂时不能打开
- 打开的表是在后台统计的，通常比想象的多
- Tomcat启动时会创建数据连接池，MySQL为了使外部连接看起来统一，会为每个连接打开一张表，比如有四个并发会话连接，都打开book table时，就会打开四张表
- MySQL可以设置最大连接数，最大打开表的数量。不能开太多，会占用内存，提升复杂性
- 表只有在evict cache或者flush时才会被认为关闭，类似于内存页的换进换出
- 内存满了会换出最近最少使用的表（替换策略可以换）
- 而在流量很大时，可能会突破内存限制，用完之后立刻关掉（比如，双十一时最近最少使用的表也只是在100ms以内，evict掉很不合理）
- 当Union时，在内存中建一张临时表进行两张表的合并，合并之后在放到disk，这也是**打开表数量超出预想的值**的原因之一
- 表的尺寸不能太大，收到文件系统文件大小的限制
- 表尺寸过大，可以分表，逻辑上可以partition，或者物理上把文件数据分开放在分布式文件系统中
- MySQL列数量有上限
- 行的尺寸也有限制，65535 bytes = 64k，但也不一定，每行的尺寸必须小于页尺寸的一半上限65535是设置page size=128k的情况
- varchar有2byte表示占用长度，nullable需要额外部分尺寸表示是否为空，这两种可能导致行尺寸超出容量限制



### InnoDB

- Optimize storage layout，类似文件碎片整理，还能增加局部性
- 事务AutoCommit，可以多个写操作放在一个事务，关掉AutoCommit，不必每次flush
- long running tx的roll back，部分已经落盘，回滚有额外开销
- long running tx应该拆分成小的tx
- Cache放大一些
- 当tx里边全部是select，MySQL会进行优化（开启只读事务，隔离等级不一样，no-locking select statement）
- rollback要redo、undo，buffer开的大，可以记录操作结果，恢复很容易，比记录操作容易



导入大量数据：

- 关掉AutoCommit

- data loading有大量有insert，若开启AutoCommit，每次都要flush，开销大

- 唯一索引约束插入时会检查唯一性，关掉AutoCommit，会load在内存，内存中检查唯一性比硬盘检查更快
- 使用多行插入
- 整数递增主键间隔设置为2，多线程插入防止冲突



优化Query：

- 主键默认做索引，不要指定太多、太长的列
- 经常访问的列，建其他索引，而且是复合索引而不是多个单独索引
- 尽量声明not null



优化Disk I/O

- 内存不够必然在内存和硬盘换进换出，CPU占用率就高；CPU不忙时，没有频繁的换进换出，那这是怀疑Disk I/O时瓶颈
- 解决方案之一是扩大内存
- 还可以优化flush策略，减少flush
- 还可以指定脏页超过阈值就flush
- DMA直接硬盘访问，跳过内存
- 换硬盘！整一个非旋转性的（比如SSD）！
- 随机读取用SSD很快，而HDD就不太行，但是顺序读取时SSD和HDD性能其实差不多的。HDD保存数据时间比SSD更长。
- 当有500G的SSD和2TB的HDD，fusion storage融合存储，设计一些维度，把不同访问模式的数据放在不同的存储介质上



预抓取Read ahead：

- 缓存在从硬盘读一个表时，会把某一行数据所在的一小块load到缓存
- 后边也有可能接着在下一次读取，这个想法时make sense的
- 因此会预抓取，把下边的也读进来
- 不能一次预抓取太多了，要控制预抓取的数量，因为预抓取是基于判断的，猜错一次开销很大
- 预抓取的策略可以优化



删数据：

truncate table而不是delete，truncate直接抹除



## 11.01

### InnoDB Buffer

table open cache：存的是table handler

InnoDB buffer：存的是数据

buffer很多块，每个之间是独立的，就是很多buffer实例

每一个实例会有多少内存

buffer实例数x每个buffer的大小是总的大小，但是每块缓存的大小需要是128M的整数倍



为什么要有多个实例？提高并发性，不同线程不在同一个实例操作

必须有很大的内存才会分实例，否则不会分实例



访问数据时，首先去table-open-cache看能不能打开一个表，取table handler

然后再去InnoDB-buffer找data



buffer如果放不下了需要清除缓存，就会使用LRU的方法换出一块数据

但是如果是请求count或者sum，需要扫描全表，而且被换到内存之后，短时间又不会被访问，因此设置最热是不合理的

因此新的进来的数据不会是hottest，而是LRU策略排序的3/8的位置



缓存读取数据时，会进行optimize，减少碎片、增加有序性

既然数据已经是有序性的了，为什么不多读取一些？可以多读一点

随机的读一些数据，防止需要的时候才去硬盘找，减少开销



数据全部加载到buffer，会有写操作的，经常把数据write back到硬盘上去

一旦dirty页的数量超过阈值，就触发flush的动作，整个buffer的脏页写到硬盘上去

写完之后，数据仍然保存在内存里，只是说把bitmap的dirty bit清除掉

多线程进行flush，线程数可以设置，一般设置为instance的数量

可以将memory的数据周期性的写到硬盘，这样进行warm-up的时间就会减少，不用重新根据用户的读写重新慢慢load，而是一次性直接load 8G进来（不一定是8G，看buffer大小）



把cache分成多个区，指定哪些表只能缓存在哪些区（hot、warm、cold等区）

hot和cold都比较小，warm最大

都是缓存，hot和cold的cache有什么区别？

- 管理内存的方式应该是有差异的
- 存在hot => warm => cold的逐渐流动



加载时还要注意，索引加载到cache是加载所有的索引还是不加载叶子节点？

- 可以设置的

- 如果是UUID，加载叶子节点，会占用很大空间
- 可以不加载叶子节点，这样加载的索引就非常多，省一半空间，虽然读取时需要再加载，但是缓存会省很多，可以放更多的索引



如果要enlarge cache：

- 先写dirty page
- 然后把所有的缓存都删掉
- 重新分配一次内存
- 这样会导致重新构建缓存，和重启没区别



Prepare Statement：

- 把已经解析编译好的sql语句存下来
- 以后再来一个相似的语句，直接用，比较快



trigger：

如果我在user表有一个balance，但是在这一列上边有一个数据约束

当insert时会触发trigger检查是否符合constraint



存储过程：

- client通过tomcat访问mysql
- 如果没有存储过程，全都要在tomcat里边load然后计算，这样会很占用内存
- 但是如果在mysql写存储过程，靠近数据源，传输数据量少



### Backup& Recovery

逻辑备份还是物理备份？

全量备份还是增量备份？



逻辑 & 物理：

物理备份：

拷贝文件出来，好处是数据库很大时备份出来的东西小，而且不用转换成脚本，速度快，还可以备份log。但是可迁移性不好，必须是同一个版本的mysql，还会对硬件有要求，而且导入数据时，必须关掉mysql



逻辑备份：

生成脚本，可迁移性强，而且可以在运行时recover，粒度可以细粒度控制，删掉一些行也是可以的。但是导出的文件大，而且生成脚本，导出速度慢



备份是remote还是local？

如果mysqldump的方式生成脚本，是可以返回给服务器的

但是如果是生成特定格式分开的文件，是在数据库机器本地的



snapshot：

copy on write的方式，存储的很少，没有一次性直接copy

没有修改的数据是没有copy的，在以后恢复，是拿初始内容加上snapshot的内容拼接起来的数据

少量数据就可以记住某一个时间点的快照

快照是一个逻辑的副本，没有直接copy，不然要存储爆炸了



全量 & 增量：

全量备份：

直接进行简单的拷贝

在做完全量备份的时候，之前的bin log都可以删掉了，不然太占用空间

做全量备份时，要先锁表，flush，文件全部一致才可以进行拷贝



增量备份：

写入bin-log，存储的是sql语句

bin-log可以进行压缩和加密，就可以减少空间，防止被别人看见

 bin-log也是可以导出的



Recovery：

在恢复时，找到某一个时刻的全量备份，load到数据库中，然后重新执行bin-log，就可以恢复到之前的状态



备份时可以在slave上边进行备份，这样master不用关

如果表坏了，可以用repair命令



设计全量备份的策略：

- 定期dump全部的数据到一个文件并且标时间
- dump出来的是脚本而不是文件
- dump是一个事务，all or nothing
- dump要加锁



只要做了dump，就可以删掉全部的bin-log了

只有单个数据库的dump，不会带有create和use的命令，需要先手动建数据库

如果导出tab分割的文本文件，是可以用可视化工具打开的，比较直观



dump也不单单是数据，还会把存储过程、函数、trigger等dump出来

你可以选择是不是要把业务逻辑也dump出来

## 11.04

### 选择性地 Recover

如何有选择性的执行bin-log？假如有人运行了drop database，我们可以跳过这条命令，执行这条命令之前的全部bin-log，然后重新在执行这条bin-log之后的全部命令

但是如果是一条其他的命令，比如update，即使跳过也不一定能恢复正常逻辑



### 关于存储过程和函数

如果存在业务逻辑，可以把业务逻辑放在mysql，tomcat只需要把参数发过来然后运行，这样减少mysql和tomcat之间数据发送的总量；但是这样对数据库迁移不是很友好，还有可能产生兼容性的问题

如果把业务逻辑存在MySQL里边，性能会比Tomcat高

但是在MySQL中编写业务逻辑，对于程序的编写不友好



如何选择？需要做trade-off！

如果是大量的呈现式的业务，存在大量的数据传输，可以把逻辑写在MySQL中

否则尽量写在Tomcat服务器中



### Partition

如果一个表太大，大到放不下，需要进行分割，防止出现一个特别大的文件

MyISAM不支持，只能用InnoDB

sql语句只支持分表，至于说是不是存在不同的机器上边，这个需要数据库管理系统实现

vertical的切分需要用户自己做，水平的切割叫做分区

进行表的分区，一张表被分成了物理上不同的几个部分，删除某一个分区就会很快，甚至还可以指定对某一个分区进行查询



分区最重要的是分区的逻辑：

- 离散型，数据取值是离散的
- 连续型分区

按照条件分区，每个区之间不能有重叠

分区也不一定是要平衡的，分区的条件可以自己写

甚至可以写函数，按照函数计算的值进行分区



那么能不能在两列上边分区？（多个列）

可以！

多列分区，会按照每一列的条件进行判断，是按照tuple的比较

```
(1, 5) < (2, 3) # True
(2, 8) < (2, 6) # False
(1, 2) < (1, 2) # False
```

按索引依次比较对应元素
如不相等，则结果为元组比较的结果(如上第1行代码)
如相等，则比较下一对元素，直至有结果(如上第2行代码)
如所有对应元素都相等，则判为相等(如上第3行代码)



less than (5,12)

那么比较 (5,10)  (5,11)  (5,12) 前两个都是true，第三个是false



- 多列分区，会按照每一列的条件进行判断，是按照tuple的比较

- 还可以按照LIST分区，每一个LIST中的值在一个区。但是LIST分区，只承认在LSIT中出现的数据，如果找不到对应的，就会报错

- 还有哈希分区（hash partitioning）和线性哈希分区（linear hash partitioning），还支持自定义hash函数

- key partitioning键分区
- subpartitioning可以进一步细化



如果是range分区，null的值对应的是minvalue，一定会被分到最小的分区里边

如果是list分区，null需要单独处理，任何一个list都没有null就会报错

如果是hash和key，null会把它的值当作0计算



把一个分区删掉之后，数据也就没有了

删除分区之后再去插入数据，插入的位置可能会改变

分区会做搜索剪枝的操作，搜索限制在小的范围内，筛选掉了大量无关数据



如果需要加新的range或list分区：

- 在后边追加分区，不能在中间加新的分区
- reorganize才能在中间搞新的分区，其实就是整个重新组织了一遍



对于hash和key分区：

- 不能drop
- 可以merge
- 所有的数据都要留下来，但是分区的数量发生了变化，需要重新组织



T2复制表T1的结构，但是删掉分区

T1是分区的，可以把T1的某些分区交换到T2，这样T2就有了数据

对T2在加入一些数据，再交换回去，就不行了



## 11.08 NoSQL & MongoDB

NoSQL：not only sql

支持schema不严格的存储



大数据场景下，数据量大的问题：

- 数据能不能存的下
- 如果存的下，能不能快速读出来=>多个盘



100G的10个硬盘，可以每个人的100G数据存到10个硬盘上边，每个10G，这样等于说每个人的读写速率提升了10倍

数据组织成分布式存储，利用率没有降低，但是速度提高了

但是这种组织方式使得故障率提高，需要冗余来提高可靠性



当我们引入分布式存储，数据分布在多个硬盘上，每一部分处理完，合起来结果可能不是最终的结果



为什么在分布式场景下，关系型数据库不太行了？

- 数据太多，表太大的话性能不好
- 如果进行分表，或者分区，都会引起在多台机器、多个表之间的连接问题



NoSQL支持非结构化、半结构化的数据，有没有一个字段和字段可以为空时完全不同的概念



### MongoDB

MongoDB支持auto-sharding，因为它都是键值对，不存在连接问题

document是MongoDB的基本数据单位

document的集合就是collection，对应的是表

每一个document有一个special key "_id"，在collection中是独一无二的

但是一个collection的documents可以有不同的shape和type

document是许多键值对，可以放很多键值对，但是键值对是有序的

document的中的key大小写敏感，类型敏感，一个document中不能有相同的键



## 11.11 MongoDB

MongoDB是键值对，可以是异构的，没有相同的schema

可以查询某些document不存在而另一些document存在的的键



### Sharding

- MongoDB拿很多服务器存储，每一个服务器叫做shard server

- 有一个config记住collection被切成多少块，在哪些server上边

- MondoDB的collection被分成了chunk，每一个collection都可以被分布式地存在不同的shard server上边

- 可以根据ID分成不同的chunk，chunk存储在不同的shard server上边

- 分好范围之后，生成document是会生成ID，就知道应该放在哪一个chunk上边

- 当chunk超过限制的大小，chunk会分裂成两个

- 会保证所有shard server上边的chunk数量相差小于2，一旦超过，就会对chunk做迁移

- 因此保证负载均衡，如果指定chunk size 64MB，那么每一个shard server的负载差距不超过128MB

- 但是可以关掉这个chunk的自动迁移，在特殊场景下是很有用的



### 图数据库

在拿节点和边描述数据的结构

关系型数据库的多对多很难真是描述，而且需要做很多表和表之间的连接



怎么存？查询语言？

节点上打标签，就表明了类型

节点之间的边表示了节点之间的关系



Querying Graphs：Cypher语法

很复杂，摆烂了



搜索的过程就是按照边的结构特征进行遍历

关系型数据库是在做笛卡尔积，join操作，巨慢无比

图数据库可以做协同过滤：Alice喜欢一本书，看看喜欢这本书的人还喜欢什么，推荐给Alice



Neo4j可以变成jar跑在Tomcat里边，也可以单独跑一个服务器内嵌在server里边，嵌入式的。

每天启动一个，把数据存下来，不希望数据在一台服务器上，



### 图数据库的Data Model

第一个节点，下一个节点是谁，下一个属性是谁

类似于链表，用双向链表存储关系，比关系型数据库的join操作要快



## 11.15

### Neo4j应用

数据清洗

Neo4j切图，每一张图负责一部分

把图塞道神经网络里边

寻找洗钱网络是不能直接写sql语句的

需要构建集群，使用机器学习



### 混合存储的问题（行存储？列存储？）

行存适合OLTP场景：

- 保证加载一次就可以把数据load到内存里



列存适合OLAP场景：

- 经常需要拿到所有数据的某一个字段，这种情况下行存储需要把所有数据load到内存但是只取一个字段，有很大的overhead
- 如果数据太大，可以分块存储，这在HBase中可以体现



当需要同时支持OLTP和OLAP时怎么搞？有两种策略：

1. 数据存储两份，一份行存，一份列存
2. 数据只存储一份，如果事务型操作多就行存储，如果分析型数据多就列存储



### B树和B+树

B Tree 和 B+ Tree也是数据库的一种存储方式

B Tree中间节点也可以存放值

B+ Tree把数据全部放在叶子节点，只存key不存value。而且B+树的叶子节点有指向兄弟节点的指针，支持Range Query

但是插入操作可能导致连续的分裂，有空间放大率

而且存在很多空洞，对内存造成浪费



### log-structured merge tree

是kv-store，有增删改查的接口

分层结构，每一层是上一层的几倍大小

内存中有一层，读写都在是对内存的直接操作

为了防止崩溃，会有WAL

内存有两块，一块写满之后，立刻切换到另一块，同时满的那一块进行flush到L0

L0的key是有重叠的，但是在进行compaction时进行多路归并排序

L1之后的层都不能有key的重叠

bloom filter可以加速查找过程



由于LSMT新数据在上层，因此读热数据性能比较好



空间放大率：

- 基本没有，数据禁止排列的

时间放大率：

- 读放大：读的时候，时间放大率会比较高，如果找的时不存在的数据，会一直读到最后一层

- 写放大：写的时候，可能每一层都满了，就需要进行连续的compaction

有索引块，找到offset，因此字符串可以任意长

为了节省空间，不是对任意一个kv都存储，它会进行优化，可能是找出key额公共前缀进行分组存储



CRC循环校验码，如果按行存，每一行进行一个CRC的计算就可以

但是如果按列存，怎么知道每一行的数据是否是对的？

按列存，追加一些数据，CRC是不是会改变？

按行存，key有公共部分，可以存成一个，但是如果按列存，会比较复杂



### RocksDB

rocksDB默认按照行存

大量写操作进来，高并发，低延迟

数据统计，读操作，低并发、高延迟



#### rocksDB写阻塞问题

写流程：

优点：

- 低延迟插入
- 写入内存直接返回
- 后台进行异步的写入硬盘

缺点：

- L0写满时将阻塞内存到磁盘的flush的过程
- L0下沉，compaction过程无法多任务执行
- 异步写，写放大严重，容易磁盘变成瓶颈
- 降低了transaction processing的可用性

优化：

- 中间层缓存数据（多加内存，满了立刻切换？）
- 负载均衡



#### 读放大问题

需要访问所有可能的数据文件

解决方案：

- 新列存结构
- 在线混合存储决策



### 常见的列式存储

Row Group格式

行列折中格式



常见的行列混合存储决策算法：

- 行列对等存储
- 行列差异存储
- 基于查询的分析



## 11.18 时序数据库

时间序列数据库：数据上带有时间戳

如果用关系型数据库

| id   | timestamp       | price | account |
| ---- | --------------- | ----- | ------- |
|      | xxxxxxxxxxxxxxx |       |         |
|      |                 |       |         |

时间戳占用空间太大

时间戳不能当主键，可能会有同一时刻很多条记录

而且时间戳当主键导致索引太长

如果数据库内的数据过多，老旧的数据还要不要？存活多长时间？



如果是时序数据库，像是一个环形队列，满了之后会删掉最旧的数据

时序数据库的特点：

- 数据压缩之后，相比于关系型数据库可以存放更多的数据
- 数据都比较简单，没有relation



### InfluxDB

- InfluxDB内有很多Bucket，每一个bucket是同一个结构
- bucket第一列是时间戳，这是必须有的，时间非常精确
- measurement，即对数据做一下分类，对bucket中的数据分组之后描述一下是干嘛的
- tag，tag上边会建索引。tag也有tag key和tag value
- field有key和value，field上边不建索引。从field set是同一个时间点上采集到的所有数据的集合。采集到的数据一定是以field的方式存储，但是field不做索引，如果一个field经常使用，需要把它转成tag



为什么field不能建立索引？

和数据的存储方式有关，field这种存储方式没法建立索引

| 时序数据库中的field | 关系型数据库 |
| ------------------- | ------------ |
| 100                 | 100          |
| +1                  | 101          |
| -1                  | 100          |

tag和field之间是可以相互转换的



能不能有多个tag？最好不要

比如既有bees又有ants，但是某一时刻来的数据只有bees，没有ants，就没法放了。

他们其实不能放在一个bucket里边，放在两个bucket中是比较好的



所谓时间序列是指针对某一个相同的东西，只是时间上不同，他们构成一个序列。而把ants和bees放在一起是没有意义的



InfluxDB和RocksDB类似，插入操作也是后台进行的，严格限制更新和删除

如果你进行删除和更新，就会停掉数据的插入，执行完query再接着插入数据（采样）



InfluxDB如果数据向下落，就说明是老旧数据，会进行压缩；而内存中的数据是不会进行压缩的

为了有比较好的性能，最好batch process

接收到数据后，组成一个batch再存入数据库，不要一条一条插入

一旦写入硬盘，旧的内存就被删掉了



InfluxDB是以列存储的方式进行存储：

- 利于数据压缩（看上边的例子）



序列的key要做索引，key是measurement + tag + field，索引不需要那么多，只有这一种



时序数据库的数据特别多，数据量巨大：

- 支持分布式，可以切成shard
- shard针对的是落在硬盘上的数据
- measuerment是逻辑上的东西，而shard是针对的物理上存储，分成不同的文件



默认情况下，只有一个shard，可以自行指定shard的存活时间

可以指定新的shard不压缩，旧的数据shard进行压缩

不能为过去的数据做shard

由于InfluxDB的数据时间戳是单调递增，因此数据不存在时间上的overlap



### 总结一下NoSQL

MongoDB

Neo4j

RocksDB & LevelDB

InfluxDB

Lucene & Solr & ElasticSearch



Dao把多个Repository组合起来拿到数据，Entity，本质还是TP（事务型处理）

如果要做AP，那么我们需要DataWarehouse

但是这么多数据库，怎么进行统一便捷的管理？DataLake



## 11.22 云原生数据库 & DataLake

### 云原生数据库

云原生数据库：未必是关系型数据库，还可以是非关系型数据库

云原生数据库，依托于云平台，结合了一些硬件设施进行优化



数据库在云上的特点：

- 虚拟化，资源的池化：目的是提高资源的利用率
- 资源耦合：将CPU、内存、硬盘等资源解耦合每一层单独调用，crash可以立刻从资源池寻找新的替代
- 弹性：即插即用，便于扩展
- 规模化
- 执行计划、分配
- 数据读写、共享存储



share nothing，通过网络传输

带来的问题：

TCP/IP传输，会进行packet的封装，导致CPU负荷过大

现在出现了新的技术，不经过OS、kernel，直接把包给到网卡，然后发出去，很快

网卡、路由器、交换机等网络设备需要支持RDMA，通过高性能网络访问其他设备上的数据



### 计算下推

云原生还有一个特点：计算下推

云原生的计算节点和存储节点是分离的，缺点是存储节点的计算资源被浪费了

而且存储节点会把大量数据发送给计算节点，导致内部的带宽占用很大

如何利用存储节点的计算资源？

计算下推！

在进一步思考，能不能下推到存储介质上边？

总之没最终的目的就是，通过不断地计算下推，减少内部的数据流动，分摊压力，充分利用计算资源

可惜的是，上述的设计是没有统一的标准的，需要结合硬件资源和特殊的设计才可以完成，这也是云原生强大的特点



视图：

物化视图在cache里边，存一下元数据和哪一个物化视图最匹配

物化视图存在重复数据，可以进行一些集合操作，不用加载那么多



### 数据仓库

当业务变大，会产生其他系统

如果进行数据分析，可能对多个主题进行操作



那么如何对不同数据库的数据做一个拼接耦合？

1. - ETL：数据的清洗、转化、加载
   - 多个数据源的数据首先进行一次转换
   - 数据在加载时，可能需要进行某些语义、数值、类型的处理
   - 数据清洗，删除dirty data
2. - 数据建模，按照OLAP的需求进行建模
3. - 进行分析、可视化



在数据仓库中，主要针对的时OLAP的处理，就是为了做分析的。数据仓库的数据源是非常多的



shard server的模式是share nothing，并行处理性能很好，但是一旦涉及到互相之间的交互，就寄了



### 数据湖

数据湖中的数据时存在各种格式的，不需要做ETL

进行元数据管理

进行分析时在把数据从数据湖抽取出来，导入到数据仓库



### 湖仓一体

当所有数据都被数据仓库用到时，就等于说数据湖全部数据被复制了一遍，等于多做了一次复制

因此有人提出湖仓一体的概念

而且根据数据的类型，在进入时就可以决定放在数据湖还是数据仓库



### 对比数据仓库和数据湖

| 数据仓库                         | 数据湖                                     |
| -------------------------------- | ------------------------------------------ |
| 数据体系严格，提前建模（OLAP）   | 数据体系松散，事后建模                     |
| 灵活性较低                       | 灵活性较高                                 |
| 数据治理容易                     | 数据治理困难                               |
| 数据种类单一（结构化、半结构化） | 数据种类丰富（结构化、半结构化、非结构化） |
| 面向成熟数据的企业级分析与处理   | 面向异构数据的科学探查与价值挖掘           |
| 向特定引擎开放，易获得高度优化   | 向所有引擎开放，各个引擎有限优化           |



## 11.25 Clustering

### 会话粘滞性

load-balance策略：

考虑连接数

最简单的是round-robin轮询

可以改变weight

如果是按照IP的hash，可以解决会话粘滞性的问题，但是不能做到负载均衡



解决会话粘滞性的问题还可以使用第三方工具存储session

比如，用redis存储session，这样集群服务器都会向redis取session

- 缺陷是redis单点故障：可以备份
- 向redis取session会稍微慢一点



### 数据库集群

MySQL主从备份

至少有三个节点

MySQL集群的作用：

- 可以做数据备份，如果主节点炸了，不至于数据全都没有
- 从节点可以分担读请求，但是写请求还是只能在主节点上边响应
- 设置好种子，集群可以动态增加



主从备份：

- cold：只写一个，每隔一段时间进行数据同步
- warm：每隔一小时更换主从节点的角色，进行切换
- hot：拿到请求，各处理各的，同时进行



还可以是多个primary



## 11.29 虚拟化 Virtualization

JVM把bytecode翻译成机器可以听懂的东西，Java可移植性比较好



VM：对CPU和内存做直接的虚拟化，对IO操作经过特殊的虚拟机转化为对物理机的操作



Image文件切分，如果Image文件有相同的部分，则可以对相同的部分进行复用

Docker+K8S

KVM+Open Stack

监控的数据都放在时间序列数据库中



虚拟机运行的是完整的操作系统。虚拟机的目的是做隔离，但是跑完整的操作系统占用空间太大了

docker是把对linux的的调用转换为对物理机操作系统的调用



containr是一个运行时。容器就是把你写的代码和需要的东西全部打包运行

docker是分层打包的

docker的image没有包含完整的操作系统

拿一个Image可以运行多个实例，App的系统调用发送给docker引擎，转换为host machine的系统调用

容器互相之间是隔离的，每个容器都有自己独立的IP

可以通过IP加端口访问container，也可以通过端口映射访问container

一个docker不能直接访问另一个docker的内容，必须通过网络进行访问



*（这一段是在讲什么啊我焯）*

*java代码需要JVM来加载，JVM是用java写的*

*最初的ClassLoader是用C写的*

*在打包时，不应该把MySQL驱动放在/lib/ext中，不要直接打包*

*ClassLoader也是一种隔离*



docker run的一些参数

- -d 后台运行，守护进程
- -p 端口映射 当前机器的xxxx端口映射道docker container的yyyy端口



内容持久化container之间的内容是完全隔离的

写入container的文件，重新启动一个ubuntu的实例，是没有之前写入的文件的，不会保存在Image中

能否持久化？Volume！

可以将volume mount到container中（文件映射）



通常volumn是一个文件，但是：

- 挂载数据库？
- 远程文件？



是可以挂载远程目录的

同一个Image在跑不同的实例可以挂载不同的volume，就不会相互干扰



## 12.30 Put them all together

A问B请求，不想要数据的结构，想要的是高级信息，比如今年的业绩blabla



烟囱：各个部门、公司之间孤立的数据系统

因此要构建数据中台：

- 聚合、治理跨域的数据，封装成服务，供前台业务调用
- 企业内外部异构的数据采集、治理、建模、分析、应用，使数据对内优化体改业务，对外可以使数据合作价值释放，成为企业资产管理中枢



层次划分：

1. 数据层：高压数据流，数据接入接口
2. data hub数据集成
3. 计算层：数据计算引擎（比如AI模型等），大数据平台（允许拿到集成完的数据），云平台数据库
4. 服务层：搞搞服务什么的



数据中心建设思路：

1. 数据清洗与转换
2. 数据弹性存储
3. 数据融合（基于并行处理基础设施）
4. 面向应用的数据服务（最终给用户暴露的东西）



key points：

1. **统一时空**基准下的数据融合（时间：统一授时，空间：空间基准相同，就好像是对空间的描述）
2. 面向xxxx的数据架构（物理实体：船，虚拟实体：航线），搞搞“数字孪生”
3. 精细化的数据治理（统一数据表征）
4. 弹性存储与处理计算基础设施



- 数字化（把东西存在电脑里），数据化（做过处理，能够进行一些操作）

- 物理世界的数字化
- 数字资产化、资产数字化赋能平台



### 总结一下！

#### 服务器端开发

- 大二的时候，tomcat访问mysql，解决了结构化数据的存储
- tomcat是java的一个进程，要控制实例数量
- Scope控制实例数量，实质是节约内存资源
- tomcat访问mysql，一般是同步调用，导致阻塞。大量请求，可以改用异步的通信方式：发消息。记下来之后说我收到了，事后处理。但是事后处理的前提是，有空闲时候，可以做到削峰填谷。如果一直很忙，全是峰，就寄了。

#### 事务

事务用描述性的方式

requires_new不是嵌套事务，根本不是一回事

同步，用锁

wait-notify

cache

异构，WebService，SOAP

WebService里边为什么要用微服务

微服务的各个服务之间比较独立，一个崩了其他的没事，而且可以独立地加资源

所有服务可以启动多个实例，但是写好的代码不可能知道各个实例在哪里，因此有一个注册中心

用户发请求到GateWay，然后GateWay在注册表上边找一下，进行调度

好了，你的应用现在很牛逼了！

#### 数据库

关系型数据库四节课

MySQL缓存-打开的表有哪些，索引有哪些

缓存大小有限制



备份：

- 集群主从备份

- 逻辑备份bin log，可以跨版本甚至跨数据库
- 直接拷贝文件做物理备份，比bin log省空间，但是会有版本问题
- partition，判断做partition有没有好处



讲完MySQL拓展出了一堆其他东西



MongoDB

- 面向document
- 表叫做collection
- 同一个collection的schema可以不一样
- MongoDB的sharding根据key进行sharding



Neo4j：

- 图数据库
- 好友关系，社交网络



LSMT InfluxDB：

- WAL
- LSMT没有空间放大，但是有读放大：全部读完才能判断有没有，写放大：有可能很多compaction



Datalake：

- 数据库很多，怎么放在datalake里边



当太多的时候，做分布式集群，集群的会话状态维护：

- gateway+register
- nginx



docker：

- 每一个docker有独立的ip
- 容器化部署
- 要有一个容器管理的功能，K8S



如果在云里边：

- cloud computing
- edge computing



hadoop：

- MapReduce并行计算，但是效率不高，读写硬盘太多



Spark：

- 不读写硬盘，进行内存操作
- RDD，分布式内存



storm：

- 上边的都是批数据
- 流式处理用storm



HDFS：

- 本地文件系统上边构建出HDFS
- 在HDFS上构建出HBase数据库和Hive数据仓库
- HBase可以数据切分
- Hive在load时候不做校验，而是在做sql式校验
